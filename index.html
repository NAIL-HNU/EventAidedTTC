<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="Event-Aided TTC ECCV2024">
  <meta property="og:title" content="Event-Aided Time-to-Collision Estimation for Autonomous Driving"/>
  <meta property="og:description" content="Event-Aided TTC ECCV2024"/>
  <meta property="og:url" content="https://nail-hnu.github.io/EventAidedTTC/"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="https://nail-hnu.github.io/EventAidedTTC/static/image/banner.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="360"/>

  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="Event-Aided Time-to-Collision Estimation for Autonomous Driving">
  <meta name="twitter:description" content="Dense Pixel Tracking via Quasi-3D Optimization">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta property="twitter:image" content="https://nail-hnu.github.io/EventAidedTTC/static/image/banner.png" />
  
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="Event cameras time-to-collision autonomous driving">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title> Event-Aided Time-to-Collision Estimation for Autonomous Driving </title>
  <link rel="icon" type="image/x-icon" href="static/images/NAIL.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-PT9E54MT3K"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-PT9E54MT3K');
</script>
  
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Event-Aided Time-to-Collision Estimation <br> for Autonomous Driving</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://scholar.google.com/citations?hl=en&user=csfnTk4AAAAJ/" target="_blank"> Jinghang Li</a><sup>1*</sup>,</span>
                <span class="author-block">
                  <a href="https://scholar.google.com.tw/citations?user=0z2qluIAAAAJ&hl=zh-TW&oi=ao/" target="_blank"> Bangyan Liao</a><sup>2*</sup>,</span>
                  <span class="author-block">
                    <a href="https://scholar.google.com.tw/citations?user=my5DtVMAAAAJ&hl=zh-TW&oi=ao/" target="_blank"> Xiuyuan LU</a><sup>3</sup>,</span>
                    <span class="author-block">
                      <a href="https://scholar.google.com/citations?user=XZczNEEAAAAJ&hl=en&oi=ao/" target="_blank"> Peidong Liu</a><sup>2</sup>,</span>
                      <span class="author-block">
                        <a href="https://uav.hkust.edu.hk/group/" target="_blank"> Shaojie Shen</a><sup>3</sup>, and</span>
                        <span class="author-block">
                          <a href="https://sites.google.com/view/zhouyi-joey/home/" target="_blank"> Yi Zhou</a><sup>1&#x2709;</sup>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block"> 
                      <sup>1</sup> Neuromorphic Automation and Intelligence Lab (NAIL), Hunan University <br> 
                      <sup>2</sup> School of Engineering, Westlake University <br> 
                      <sup>3</sup> Aerial Robotics Group, HKUST <br>
                      European Conference on Computer Vision (ECCV), 2024
                    </span>                    
                    <span class="eql-cntrb"><small><br><sup>*</sup> Equal Contribution&nbsp;&nbsp;<sup>&#x2709;</sup>Corresponding author: <a href="mailto:eeyzhou@hnu.edu.cn">eeyzhou@hnu.edu.cn</a></small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                      <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://NAIL-HNU.github.io/EventAidedTTC/static/pdfs/main_paper.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <span class="link-block">
                      <a href="https://NAIL-HNU.github.io/EventAidedTTC/static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://NAIL-HNU.github.io/EventAidedTTC/" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="http://arxiv.org/abs/2407.07324" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <!-- Your video here -->
        <source src="https://nail-hnu.github.io/EventAidedTTC/static/videos/experiment_result.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Real-world Experiments.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Predicting a potential collision with leading vehicles is an essential functionality of any autonomous/assisted driving system. One bottleneck of existing vision-based solutions is that their updating rate is limited to the frame rate of standard cameras used. In this paper, we present a novel method that estimates the time to collision using a neuromorphic event-based camera, a biologically inspired visual sensor that can sense at exactly the same rate as scene dynamics. The core of the proposed algorithm consists of a two-step approach for efficient and accurate geometric model fitting on event data in a coarse-to-fine manner. The first step is a robust linear solver based on a novel geometric measurement that overcomes the partial observability of event-based normal flow. The second step further refines the resulting model via a spatio-temporal registration process formulated as a nonlinear optimization problem. Experiments on both synthetic and real data demonstrate the effectiveness of the proposed method, outperforming other alternative methods in terms of efficiency and accuracy. 
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Datasets Overview</h2>
      <div style="text-align: center;">
        <img src="https://nail-hnu.github.io/EventAidedTTC/static/images/setup_overview.png" alt="sys" width="1280" height="720" />
      </div>
        <h2 class="subtitle has-text-centered">
          Illustration of our datasets and devices for data collection. 
           (a) A selected snapshot of the synthetic dataset, on each side of which the intensity information and the events (with a naive accumulation) are illustrated, respectively. 
           (b) The configuration of the small-scale test platform. 
           (c) The multi-sensor suite mounted on a car.
        </h2>
    </div>
  </div>
</section>

<div class="hero-body">
  <div class="container">
    <!-- <h2 class="title is-3">Hardware Structure</h2> -->
    <section class="hero teaser">
      <div class="container is-max-desktop">
        <div class="hero-body">
          <video poster="" id="tree" autoplay controls muted loop height="100%">
            <source src="https://nail-hnu.github.io/EventAidedTTC/static/videos/dataset_intro.mp4" type="video/mp4">
          </video>
          <h2 class="subtitle has-text-centered">
            The details of three datasets we collected and their corresponding data collection hardware.
          </h2>
        </div>
      </div>
    </section>
  </div>
</div>


<!-- Dataset links -->

<!-- Carla dataset Links -->
 <div class="hero-body">
  <div class="container">
    <h2 class="title is-3">Dataset Links</h2>
      <h3 class="title is-4 has-text-centered">Carla Synthetic Data Sequences</h3>
      <div class="columns is-centered is-vcentered">
          <div class="column is-half">
              <figure class="image">
                  <img src="https://nail-hnu.github.io/EventAidedTTC/static/images/carla.gif" alt="Left Sequence GIF" width="425" height="240">
              </figure>
          </div>
          <div class="column is-half">
            <div class="columns is-multiline">
              <div class="column is-full">
                  <h4 class="title is-6">Suburban Const. Vel</h4>
                  <ul>
                    <li>rawdata for 8 types of vehicles: <a href="https://drive.google.com/drive/folders/1BdNs93O-P8CuCdzP3Tz-K2Qrxia-S2qL?usp=sharing">rosbag (197M)</a> </li>
                    <li>calibration: <a href="https://drive.google.com/file/d/1N5amhdVXkf9aQZx1ke15XnfYjQd91PWI/view?usp=sharing">mat (1K)</a> </li>
                  </ul>
              </div>
              <div class="column is-full">
                  <h4 class="title is-6">Urban Const. Vel</h4>
                  <ul>
                    <li>rawdata for 8 types of vehicles: <a href="https://drive.google.com/drive/folders/1QVPaVk0YszNkUv7PzA4LHNkc8HZ36oak?usp=sharing">rosbag (223M)</a> </li>
                    <li>calibration: <a href="https://drive.google.com/file/d/1x1x6Fng_nsngNpOhTerJhghXKVZvICiU/view?usp=sharing">mat (1K)</a> </li>
                  </ul>
              </div>
              <div class="column is-full">
                  <h4 class="title is-6">Suburban Accelerate</h4>
                  <ul>
                    <li>rawdata for 8 types of vehicles: <a href="https://drive.google.com/drive/folders/1TEEtbbJRYn12i65wKBv1YL2p-aHNIsmK?usp=sharing">rosbag (202M)</a> </li>
                    <li>calibration: <a href="https://drive.google.com/file/d/1apxuvuhi7c7vyE9iM9S1LX4NqAgFcLk0/view?usp=sharing">mat (1K)</a> </li>
                  </ul>
            </div>
          </div>
      </div>
  </div>
</div>
<!-- End Slider Dataset links -->


<!-- slider dataset Links -->
<div class="hero-body">
  <div class="container">
      <h3 class="title is-4 has-text-centered">Small-scale Data Sequences</h3>
      <div class="columns is-centered is-vcentered">
          <div class="column is-half">
              <figure class="image">
                  <img src="https://nail-hnu.github.io/EventAidedTTC/static/images/slider.gif" alt="Left Sequence GIF" width="425" height="240">
              </figure>
          </div>
          <div class="column is-half">
            <div class="columns is-multiline">
              <div class="column is-full">
                  <h4 class="title is-6">Slider 500</h4>
                  <ul>
                    <li>rawdata: <a href="https://drive.google.com/file/d/1pIMngg_zyveweRGhUh4rV1vJrniVGEj3/view?usp=sharing">rosbag (445M)</a> 
                      | bounding box: <a href="https://drive.google.com/file/d/1pkuIpNEfJQo67OnI-k6o6pyQbnr31lhY/view?usp=sharing">csv (3K)</a></li>
                    <li>groundtruth TTC: <a href="https://drive.google.com/file/d/1VOlZnZMh1dAnw6zN2KLl32pszVdXxYBn/view?usp=sharing">csv (3K)</a> 
                      | calibration: <a href="https://drive.google.com/file/d/1h5YUogbsrotCdib_ghHDwJKtnp6T7RVa/view?usp=sharing">mat (61K)</a></li>
                  </ul>
              </div>
              <div class="column is-full">
                  <h4 class="title is-6">Slider 750</h4>
                  <ul>
                      <li>rawdata: <a href="https://drive.google.com/file/d/1RblCeHK1akuPjcZjGy-N9IsPL9a4Jrmi/view?usp=sharing">rosbag (613M)</a> 
                        | bounding box: <a href="https://drive.google.com/file/d/1ie8gfp2keiVHXIjwzX_h7Qs6ceyExK8b/view?usp=sharing">csv (2K)</a></li>
                      <li>groundtruth TTC: <a href="https://drive.google.com/file/d/1mrhJplOKqOKwsOqqDe1fFcoXkbNLk1pP/view?usp=sharing">csv (2K)</a> 
                        | calibration: <a href="https://drive.google.com/file/d/1EaGqz9j8qaor678T7n4IU2iKJd4io__5/view?usp=sharing">mat (61K)</a></li>
                  </ul>
              </div>
              <div class="column is-full">
                  <h4 class="title is-6">Slider 1000</h4>
                  <ul>
                      <li>rawdata: <a href="https://drive.google.com/file/d/1xiLSPXHeoBdbvdO201OUx3IUnJGXzWUH/view?usp=sharing">rosbag (484M)</a> 
                        | bounding box: <a href="https://drive.google.com/file/d/1sFqz2tREbi07Jd4lS1nRzLFBnSpjIjr3/view?usp=sharing">csv (1K)</a></li>
                      <li>groundtruth TTC: <a href="https://drive.google.com/file/d/1iX5GeyhrnxixolBY2U40cfo3DHTRL9HB/view?usp=share_link">csv (2K)</a> 
                        | calibration: <a href="https://drive.google.com/file/d/1cTWeDiqCjmsoyFz5j015VOMIX4fDO4eK/view?usp=sharing">mat (61K)</a></li>
                  </ul>
            </div>
          </div>
      </div>
  </div>
</div>
<!-- End Slider Dataset links -->

<!-- FCWD Dataset links -->
<div class="hero-body">
  <div class="container">
      <h3 class="title is-4 has-text-centered">Forward Collision Warning Data (FCWD) Sequences</h3>
      <div class="columns is-centered is-vcentered">
          <div class="column is-half">
              <figure class="image">
                  <img src="https://nail-hnu.github.io/EventAidedTTC/static/images/fcwd.gif" alt="Left Sequence GIF" width="425" height="240">
              </figure>
          </div>
          <div class="column is-half">
            <div class="columns is-multiline">
              <div class="column is-full">
                <!-- <h4 class="title is-6">Calibration File</h4> -->
                <ul>
                  <li>Camera intrinsic: <a href="https://drive.google.com/drive/folders/1RH8MnHrv_L_Z_EQLivvwmZ4gHGLY79Lf?usp=sharing">mat (112K)</a>
                   | Lidar2RGB extrinsic: <a href="https://drive.google.com/drive/folders/1Wpgm6pMLHus4JQ4NTEYWk29xQY8aDA6X?usp=sharing">txt (1K)</a> </li>
                </ul>
              </div>
              <div class="column is-full">
                  <h4 class="title is-6">Sequence 1</h4>
                  <ul>
                    <li>rawdata: <a href="https://drive.google.com/file/d/1GoYA4pveeEVePT6JN0lZH35cVKThaOpq/view?usp=sharing">rosbag (1.01G)</a> 
                      | <a href="https://drive.google.com/file/d/1UP7mGo9Sm-FBe8cw1j51ej2hwlYa-E9Y/view?usp=sharing">hdf5 (2.22G)</a></li>
                    <li>bounding box: <a href="https://drive.google.com/file/d/160p6IE2BTUJG_4Pw3NoTYKjupV_OtfZm/view?usp=sharing">csv (6K)</a> 
                      | groundtruth TTC: <a href="https://drive.google.com/file/d/1Nq7YwqAvua4N2FZqBFq4CLHRQKdHN0om/view?usp=sharing">csv (7K)</a> </li>
                  </ul>
              </div>
              <div class="column is-full">
                  <h4 class="title is-6">Sequence 2</h4>
                  <ul>
                    <li>rawdata: <a href="https://drive.google.com/file/d/1aqD-UBiWcAdd8qms1NJyw2Xf2MivUs-l/view?usp=sharing">rosbag (518M)</a> 
                      | <a href="https://drive.google.com/file/d/1fQmlxH5JMgV6JzoxjV4XcRQ2uSkLT4fs/view?usp=sharing">hdf5 (2.01G)</a></li>
                    <li>bounding box: <a href="https://drive.google.com/file/d/1bXw7DTz0symg-liO_t4EsQJQ1cSUoxe2/view?usp=sharing">csv (7K)</a> 
                      | groundtruth TTC: <a href="https://drive.google.com/file/d/1-MTOlgYlXSa7v7MTSdux0mw2smlUd25V/view?usp=sharing">csv (7K)</a> </li>
                  </ul>
              </div>
              <div class="column is-full">
                  <h4 class="title is-6">Sequence 3</h4>
                  <ul>
                    <li>rawdata: <a href="https://drive.google.com/file/d/1Y1Ls68a3LJmr76EF27c24hCocUn0UY9E/view?usp=sharing">rosbag (503M)</a> 
                      | <a href="https://drive.google.com/file/d/1o0TWqkc6KCbHsEGwwxiVI-XyZeM5FUZZ/view?usp=sharing">hdf5 (1.99G)</a></li>
                    <li>bounding box: <a href="https://drive.google.com/file/d/1obM4PKJyX4VPhpJ8NUJ1Q3snR1StDPxw/view?usp=sharing">csv (6K)</a> 
                      | groundtruth TTC: <a href="https://drive.google.com/file/d/1gH80TDTE-rLW55fkHPAzdGCPXR5yVhn1/view?usp=sharing">csv (7K)</a> </li>
                  </ul>
            </div>
          </div>
      </div>
  </div>
</div>
<!-- End FCWD Dataset links -->
</div>
  <h4 class="subtitle has-text-centered">
    <small>If you have any questions about using the data, please contact Jinghang Li <a href="mailto:jhanglee@hnu.edu.cn">(jhanglee@hnu.edu.cn)</a></small>
  </h4>
</div>





<!--BibTex citation -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
    @misc{li2024eventaidedtimetocollisionestimationautonomous,
      title         = {Event-Aided Time-to-Collision Estimation for Autonomous Driving},
      author        = {Jinghang Li and Bangyan Liao and Xiuyuan LU and Peidong Liu and Shaojie Shen and Yi Zhou},
      year          = 2024,
      eprint        = {2407.07324},
      archiveprefix = {arXiv},
      primaryclass  = {cs.CV}
    }
    </code></pre>
  </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
